# Data Warehouse

## Introduction

In this project, you'll apply what you've learned on data warehouses and AWS to build an ETL pipeline for a database hosted on Redshift. To complete the project, you will need to load data from S3 to staging tables on Redshift and execute SQL statements that create the analytics tables from these staging tables.

## Project Datasets

You'll be working with 3 datasets that reside in S3. Here are the S3 links for each:

Song data: ```s3://udacity-dend/song_data```
Log data: ```s3://udacity-dend/log_data```
This third file ```s3://udacity-dend/log_json_path.jsoncontains``` the meta information that is required by AWS to correctly load ```s3://udacity-dend/log_data```

## Song Dataset


## How to Run Scripts

